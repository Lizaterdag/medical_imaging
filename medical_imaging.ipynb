{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2b12ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19d7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: torchvision in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: requests in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: visdom in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (0.1.8.9)\n",
      "Requirement already satisfied: websocket-client in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (0.58.0)\n",
      "Requirement already satisfied: scipy in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (1.7.3)\n",
      "Requirement already satisfied: jsonpatch in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (1.32)\n",
      "Requirement already satisfied: pyzmq in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (22.3.0)\n",
      "Requirement already satisfied: pillow in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (9.0.1)\n",
      "Requirement already satisfied: torchfile in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (0.1.0)\n",
      "Requirement already satisfied: numpy>=1.8 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (1.21.5)\n",
      "Requirement already satisfied: requests in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (2.27.1)\n",
      "Requirement already satisfied: tornado in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (6.1)\n",
      "Requirement already satisfied: six in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from visdom) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from jsonpatch->visdom) (2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->visdom) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->visdom) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->visdom) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/darwe001/opt/anaconda3/lib/python3.9/site-packages (from requests->visdom) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aba7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a4c8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchCamelyon(data_utils.Dataset):\n",
    "\n",
    "    def __init__(self, mode='train', batch_size=32, n_iters=None, augment=False):\n",
    "            super().__init__()\n",
    "\n",
    "            self.n_iters = n_iters\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "            assert mode in ['train', 'valid', 'test']\n",
    "            base_name = \"camelyonpatch_level_2_split_{}_{}.h5\"\n",
    "\n",
    "            print('\\n')\n",
    "            print(\"# \" * 50)\n",
    "            print('Loading {} dataset...'.format(mode))\n",
    "\n",
    "            # Open the files\n",
    "            self.h5X = h5py.File(os.path.join(base_name.format(mode, 'x')), 'r')\n",
    "            self.h5y = h5py.File(os.path.join(base_name.format(mode, 'y')), 'r')\n",
    "\n",
    "            # Read into numpy array\n",
    "#             self.X = np.array(h5X.get('x'))\n",
    "#             self.y = np.array(h5y.get('y'))\n",
    "\n",
    "            #print('Loaded {} dataset with {} samples'.format(mode, len(self.X)))\n",
    "            print(\"# \" * 50)\n",
    "\n",
    "            if augment:\n",
    "                self.transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                     transforms.ColorJitter(brightness=.5, saturation=.25, hue=.1, contrast=.5),\n",
    "                                                     transforms.RandomAffine(10, (0.05, 0.05), fillcolor=(255, 255, 255)),\n",
    "                                                     transforms.RandomHorizontalFlip(.5),\n",
    "                                                     transforms.RandomVerticalFlip(.5),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))]\n",
    "                                                   )\n",
    "            else:\n",
    "                self.transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #idx = item % self.__len__()\n",
    "        #_slice = slice(idx*self.batch_size, (idx + 1) * self.batch_size)\n",
    "        \n",
    "#         self.X = np.array(h5X.get('x'))\n",
    "#         self.y = np.array(h5y.get('y'))\n",
    "        # size: 96x96x3\n",
    "        image = np.array(self.h5X.get(\"x\")[idx])\n",
    "        # size: 1\n",
    "        label = torch.tensor(self.h5y.get(\"y\")[idx]).view(-1)\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        #labels = torch.tensor(self.y[_slice].astype(np.float32)).view(-1, 1)\n",
    "        #return {'images': images, 'labels': labels}\n",
    "        return image, label\n",
    "\n",
    "    #def _transform(self, images):\n",
    "    #    tensors = []\n",
    "    #    for image in images:\n",
    "    #        tensors.append(self.transform(image))\n",
    "    #    return torch.stack(tensors)\n",
    "\n",
    "    def __len__(self):\n",
    "        #return len(self.X) // self.batch_size\n",
    "        return len(self.h5X.get(\"x\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79357b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"x\": shape (262144, 96, 96, 3), type \"|u1\">\n",
      "torch.Size([1, 1, 1])\n",
      "(96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "base_name = \"camelyonpatch_level_2_split_{}_{}.h5\"\n",
    "mode = 'train'\n",
    "\n",
    "h5X = h5py.File(os.path.join(base_name.format(mode, 'x')), 'r')\n",
    "h5y = h5py.File(os.path.join(base_name.format(mode, 'y')), 'r')\n",
    "print(h5X.get(\"x\"))\n",
    "X = np.array(h5X.get('x')[0])\n",
    "y = h5y.get('y')[0]\n",
    "print(torch.tensor(y).shape)\n",
    "#img = Image.fromarray(X[0])\n",
    "# img.show()\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4f653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train dataset with 262144 samples\n"
     ]
    }
   ],
   "source": [
    "print('Loaded {} dataset with {} samples'.format(mode, len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489dc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def metrics(prediction, target):\n",
    "\n",
    "#     prediction_binary = torch.ge(prediction, 0.5).float()\n",
    "#     N = target.numel()\n",
    "\n",
    "#     # True positives, true negative, false positives, false negatives calculation\n",
    "#     tp = torch.nonzero(prediction_binary * target).shape[0]\n",
    "#     tn = torch.nonzero((1 - prediction_binary) * (1 - target)).shape[0]\n",
    "#     fp = torch.nonzero(prediction_binary * (1 - target)).shape[0]\n",
    "#     fn = torch.nonzero((1 - prediction_binary) * target).shape[0]\n",
    "\n",
    "#     # Metrics\n",
    "#     accuracy = (tp + tn) / N\n",
    "#     precision = 0. if tp == 0 else tp / (tp + fp)\n",
    "#     recall = 0. if tp == 0 else tp / (tp + fn)\n",
    "#     specificity = 0. if tn == 0 else tn / (tn + fp)\n",
    "#     f1 = 0. if precision == 0 or recall == 0 else (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "#     return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'specificity': specificity}\n",
    "\n",
    "\n",
    "def loss(prediction, target):\n",
    "\n",
    "    w1 = 1.33  # False negative penalty\n",
    "    w2 = .66  # False positive penalty\n",
    "\n",
    "    return -torch.mean(w1 * target * torch.log(prediction.clamp_min(1e-3))\n",
    "                       + w2 * (1. - target) * torch.log(1. - prediction.clamp_max(.999)))\n",
    "\n",
    "\n",
    "env = 'main'\n",
    "plots = {}\n",
    "\n",
    "def plot(var_name, split_name, title_name, x, y):\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(f'{title_name}')\n",
    "    plt.plot(x, y, label=f'{split_name}')\n",
    "    plt.xlabel(f'{var_name}')\n",
    "    plt.ylabel(f'{split_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     if var_name not in plots:\n",
    "#         plots[var_name] = viz.line(X=np.array([x, x]), Y=np.array([y, y]), env=env, opts=dict(\n",
    "#             legend=[split_name],\n",
    "#             title=title_name,\n",
    "#             xlabel='Iterations',\n",
    "#             ylabel=var_name\n",
    "#         ))\n",
    "#     else:\n",
    "#         viz.line(X=np.array([x]), Y=np.array([y]), env=env, win=plots[var_name], name=split_name, update='append')\n",
    "\n",
    "\n",
    "def sliding_window(image_shape, window_shape, stride=None):\n",
    "\n",
    "    if stride is None:\n",
    "        stride = (window_shape[0], window_shape[1])\n",
    "\n",
    "    # Padding\n",
    "    padding_x = 0 if image_shape[1] % window_shape[1] == 0 else window_shape[1] - image_shape[1] % window_shape[1]\n",
    "    padding_y = 0 if image_shape[0] % window_shape[0] == 0 else window_shape[0] - image_shape[0] % window_shape[0]\n",
    "    padded_shape = (image_shape[0] + padding_y, image_shape[1] + padding_x)\n",
    "\n",
    "    x = np.arange(0, padded_shape[1], stride[1])\n",
    "    y = np.arange(0, padded_shape[0], stride[0])\n",
    "\n",
    "    x1, y1 = np.meshgrid(x, y)\n",
    "\n",
    "    x2 = x1 + window_shape[1]\n",
    "    y2 = y1 + window_shape[0]\n",
    "\n",
    "    return np.stack([x1, y1, x2, y2], axis=2), {'x': padding_x, 'y': padding_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8058b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a53be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darwe001/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/darwe001/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "back = models.mobilenet_v2(pretrained=True)\n",
    "backbone = nn.Sequential(*list(back.children())[:-1])\n",
    "pool = nn.MaxPool2d(3, 1)\n",
    "fc = nn.Sequential(nn.Linear(1280, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156098da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd37ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darwe001/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/darwe001/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "MobileNet v2 initialized with 2.225e+06 parameters\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "\n",
      "\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "class CamelyonClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.mobilenet_v2(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.pool = nn.MaxPool2d(3, 1)\n",
    "        #self.fc = nn.Sequential(nn.Linear(1280, 1), nn.Sigmoid())\n",
    "        self.fc = nn.Sequential(nn.Linear(1280, 1))\n",
    "\n",
    "        n_params = sum([p.numel() for p in self.parameters()])\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"# \" * 50)\n",
    "        print(\"MobileNet v2 initialized with {:.3e} parameters\".format(n_params))\n",
    "        print(\"# \" * 50)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc(self.pool(self.backbone(x)).view(x.shape[0], -1))\n",
    "\n",
    "    def print_modules(self):\n",
    "        for idx, param in enumerate(self.modules()):\n",
    "            print(\"Module : \", idx)\n",
    "            print(param)\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    zeros = torch.zeros((2, 3, 96, 96))\n",
    "    model = CamelyonClassifier()\n",
    "    print(model(zeros).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f6ad938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "MobileNet v2 initialized with 2.225e+06 parameters\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "Loading train dataset...\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "\n",
      "\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "Loading valid dataset...\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "32\t\t Train Loss: 0.5744\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(losses)\u001b[38;5;241m.\u001b[39mmean(), torch\u001b[38;5;241m.\u001b[39mtensor(accuracy)\u001b[38;5;241m.\u001b[39mmean(), torch\u001b[38;5;241m.\u001b[39mtensor(f1)\u001b[38;5;241m.\u001b[39mmean(), \\\n\u001b[1;32m    134\u001b[0m            torch\u001b[38;5;241m.\u001b[39mtensor(specificity)\u001b[38;5;241m.\u001b[39mmean(), torch\u001b[38;5;241m.\u001b[39mtensor(precision)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Back-propagation\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Train Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(iteration, np\u001b[38;5;241m.\u001b[39mmean(losses)),\n\u001b[1;32m     50\u001b[0m       end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CamelyonClassifier()\n",
    "\n",
    "dataset_train = PatchCamelyon(mode='train', batch_size=32, augment=True)\n",
    "dataset_valid = PatchCamelyon(mode='valid', batch_size=32)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999), weight_decay=1e-8)\n",
    "# Loss function\n",
    "#criterion = loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    specificities = []\n",
    "    precisions = []\n",
    "    for iteration, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # Zero gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Load data to GPU\n",
    "        #sample = dataset_train[idx]\n",
    "        #images = sample['images']\n",
    "        #labels = sample['labels']\n",
    "\n",
    "        # Forward pass\n",
    "        #print(images.shape)\n",
    "        predicted = model(images)\n",
    "\n",
    "        # Loss\n",
    "        #print(predicted)\n",
    "        #predicted = predicted.type(torch.float32)\n",
    "        loss = criterion(predicted, labels.float())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back-propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"{}\\t\\t Train Loss: {:.4f}\".format(iteration, np.mean(losses)),\n",
    "              end=\"\\r\")\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        if idx % 1000000 == 0:\n",
    "            #val_loss, accuracy, f1, specificity, precision = validation()\n",
    "        \n",
    "            val_losses.append(val_loss)\n",
    "            accuracies.append(accuracy)\n",
    "            f1s.append(f1)\n",
    "            specificities.append(specificity)\n",
    "            precisions.append(precision)\n",
    "\n",
    "            # Get loss and metrics from validation set\n",
    " \n",
    "\n",
    "            # Plot train and validation loss\n",
    "            plot('loss', 'train', 'Loss', np.arange(len(losses)), losses)\n",
    "            plot('loss', 'validation', 'Loss',np.arange(len(val_losses)),  val_losses)\n",
    "\n",
    "            # Plot metrics\n",
    "            plot('accuracy', 'test', 'Accuracy',np.arange(len(accuracies)),  accuracies)\n",
    "            plot('specificity', 'test', 'Specificity',np.arange(len(specificities)), specificities)\n",
    "            plot('f1', 'test', 'F1',np.arange(len(f1s)), f1s)\n",
    "            plot('precision', 'test', 'Precision', np.arange(len(precisions)), precisions)\n",
    "\n",
    "            # Print output\n",
    "            print(\"\\nIteration: {:04d} of {:04d}\\t\\t Valid Loss: {:.4f}\".format(idx, 10000, val_loss),\n",
    "                  end=\"\\n\\n\")\n",
    "\n",
    "            # Set model to training mode again\n",
    "            model.train()\n",
    "\n",
    "        if idx % 1000000 == 0:\n",
    "            torch.save(model.state_dict(), 'models/model-{:05d}.pth'.format(idx))\n",
    "        \"\"\"\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    specificity = []\n",
    "    precision = []\n",
    "    \n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    for idx in range(len(dataset_valid)): #\n",
    "\n",
    "        sample = dataset_valid[idx] #\n",
    "\n",
    "        # Load data to GPU\n",
    "        images = sample['images'] #\n",
    "        labels = sample['labels'] #\n",
    "\n",
    "        # Forward pass\n",
    "        predicted = model(images)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(predicted, labels)\n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        \n",
    "        predictions += ((torch.sigmoid(predicted) > 0.5) * 1.0).to_list() #\n",
    "        true_values += labels.to_list() #\n",
    "        \n",
    "        \n",
    "        \n",
    "        # scikit learn classification report\n",
    "        \n",
    "        # DELETE ALL THIS USE SCIKITLEARN\n",
    "        prediction_binary = torch.ge(predicted, 0.5).float()\n",
    "        N = labels.numel()\n",
    "\n",
    "        # True positives, true negative, false positives, false negatives calculation\n",
    "        tp = torch.nonzero(prediction_binary * labels).shape[0]\n",
    "        tn = torch.nonzero((1 - prediction_binary) * (1 - labels)).shape[0]\n",
    "        fp = torch.nonzero(prediction_binary * (1 - labels)).shape[0]\n",
    "        fn = torch.nonzero((1 - prediction_binary) * labels).shape[0]\n",
    "\n",
    "        # Metrics\n",
    "        acc = (tp + tn) / N\n",
    "        prec = 0. if tp == 0 else tp / (tp + fp)\n",
    "        rcl = 0. if tp == 0 else tp / (tp + fn)\n",
    "        spec = 0. if tn == 0 else tn / (tn + fp)\n",
    "        f_1 = 0. if prec == 0 or rcl == 0 else (2 * prec * rcl) / (prec + rcl)\n",
    "\n",
    "        metrics = {'accuracy': acc, 'precision': prec, 'recall': rcl, 'f1': f_1, 'specificity': spec}\n",
    "\n",
    "        accuracy.append(metrics['accuracy'])\n",
    "        f1.append(metrics['f1'])\n",
    "        specificity.append(metrics['specificity'])\n",
    "        precision.append(metrics['precision'])\n",
    "\n",
    "    return torch.tensor(losses).mean(), torch.tensor(accuracy).mean(), torch.tensor(f1).mean(), \\\n",
    "           torch.tensor(specificity).mean(), torch.tensor(precision).mean()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa545e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
